# 预训练语言模型使用

## 1.预训练， 训练， 微调

* 预训练：指的是大公司通过大规模数据，大型网络所训练得到的模型，模型参数量往往很大
* 训练：**指的是预训练语言模型的基础上，在添加一些语料，接着训练语言模型，这对硬件的要求也很高，一般实验室玩不起**
* 微调：指的是，不是针对语言模型，**而是针对具体任务，**对上层，模型与预训练语言模型进行微调参数，其实本质上还是对上层模型进行微调，对预训练语言模型进行微调在数据量较小的情况下所起的作用不大。

一块16gb以上的显卡，你玩起来才能不那么吃力，1080ti对短文本有效，对于长文本，甚至无法微调。

## 2.微调方法

* 方案1：不冻结预训练语言模型，进行全局微调
* 方案2：冻结预训练语言模型，对上层模型进行微调
* 方案3：**先用现有数据在现有预训练语言模型上接着训练语言模型，然后再在下游任务进行微调。**

效果比较：方案3>方案2>方案1

迭代速度比较：方案1>方案2>方案3